MASTER_ADDR=npl02
MASTER_PORT=7010
NNODES=2
LOCAL RANK 0
LOCAL RANKLOCAL RANK 1LOCAL RANK 
 3TOTAL GRAD ACC STEPS2
 
Training Alpaca-LoRA model with params:
use_lora: True
base_model: FreedomIntelligence/phoenix-inst-chat-7b
data_path: input-data/whisper-large-v2/train-clean-100-clean-360-40000.json
dev_data_path: input-data/whisper-large-v2/validation-clean.json
output_dir: models/whisper-large-v2/40000
batch_size: 36
micro_batch_size: 4
num_epochs: 4
learning_rate: 2e-05
cutoff_len: 3225
val_set_size: 2703
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['query_key_value', 'dense_h_to_4h', 'dense_4h_to_h', 'dense']
train_on_inputs: False
add_eos_token: False
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model`: 
resume_from_checkpoint: False
prompt template: phoenix
9TOTAL GRAD ACC STEPS
TOTAL GRAD ACC STEPS
 TOTAL GRAD ACC STEPS 9 9
9

DDDDDD  0
0
WORLD SIZEWORLD SIZE  88  NEW GRAD ACC STEPSNEW GRAD ACC STEPSDDD  4 4

0
DDD 0
WORLD SIZE 8 NEW GRAD ACC STEPS 4WORLD SIZE
 8 NEW GRAD ACC STEPS 4
LOCAL RANK 1
TOTAL GRAD ACC STEPS 9
LOCAL RANK LOCAL RANK3
 0
TOTAL GRAD ACC STEPS 9
Training Alpaca-LoRA model with params:
use_lora: True
base_model: FreedomIntelligence/phoenix-inst-chat-7b
data_path: input-data/whisper-large-v2/train-clean-100-clean-360-40000.json
dev_data_path: input-data/whisper-large-v2/validation-clean.json
output_dir: models/whisper-large-v2/40000
batch_size: 36
micro_batch_size: 4
num_epochs: 4
learning_rate: 2e-05
cutoff_len: 3225
val_set_size: 2703
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['query_key_value', 'dense_h_to_4h', 'dense_4h_to_h', 'dense']
train_on_inputs: False
add_eos_token: False
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model`: 
resume_from_checkpoint: False
prompt template: phoenix

TOTAL GRAD ACC STEPS 9
LOCAL RANK 2
TOTAL GRAD ACC STEPS 9
DDD 0
DDDDDD WORLD SIZE 0 
8DDD NEW GRAD ACC STEPS 4 
WORLD SIZE0 8
 0NEW GRAD ACC STEPS
 4
WORLD SIZE 8WORLD SIZE  NEW GRAD ACC STEPS 84 
NEW GRAD ACC STEPS 4
DEVICE MAP {'': 1}
DEVICE MAP {'': 3}
DEVICE MAP {'': 2}
DEVICE MAP {'': 0}
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
DEVICE MAP {'': 1}
DEVICE MAP {'': 3}
DEVICE MAP {'': 2}
DEVICE MAP {'': 0}
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
trainable params: 15,728,640 || all params: 7,084,744,704 || trainable%: 0.22200715279295405
{'loss': 0.2866, 'learning_rate': 1.999600319744205e-05, 'epoch': 0.0}
{'loss': 0.2866, 'learning_rate': 1.999600319744205e-05, 'epoch': 0.0}
{'loss': 0.2977, 'learning_rate': 1.998001598721023e-05, 'epoch': 0.0}
{'loss': 0.2977, 'learning_rate': 1.998001598721023e-05, 'epoch': 0.0}
{'loss': 0.2616, 'learning_rate': 1.9960031974420465e-05, 'epoch': 0.01}
{'loss': 0.2616, 'learning_rate': 1.9960031974420465e-05, 'epoch': 0.01}
{'loss': 0.2328, 'learning_rate': 1.99400479616307e-05, 'epoch': 0.01}
{'loss': 0.2328, 'learning_rate': 1.99400479616307e-05, 'epoch': 0.01}
{'loss': 0.2495, 'learning_rate': 1.992006394884093e-05, 'epoch': 0.02}
{'loss': 0.2495, 'learning_rate': 1.992006394884093e-05, 'epoch': 0.02}
{'loss': 0.2291, 'learning_rate': 1.990007993605116e-05, 'epoch': 0.02}
{'loss': 0.2291, 'learning_rate': 1.990007993605116e-05, 'epoch': 0.02}
{'loss': 0.192, 'learning_rate': 1.9880095923261392e-05, 'epoch': 0.02}
